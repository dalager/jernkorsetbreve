{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = dacy.load('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of letters: 625\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/letters.csv')\n",
    "# only letters from Peter Mærsk\n",
    "df = df[df['sender'] == 'Peter Mærsk']\n",
    "print(f'Number of letters: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 texts\n",
      "Saving data to disk from index 1 texts\n",
      "Processed 11 texts\n",
      "Processed 21 texts\n",
      "Processed 31 texts\n",
      "Processed 41 texts\n",
      "Processed 51 texts\n",
      "Saving data to disk from index 51 texts\n",
      "Processed 61 texts\n",
      "Processed 71 texts\n",
      "Processed 81 texts\n",
      "Processed 91 texts\n",
      "Processed 101 texts\n",
      "Saving data to disk from index 101 texts\n",
      "Processed 111 texts\n",
      "Processed 121 texts\n",
      "Processed 131 texts\n",
      "Processed 141 texts\n",
      "Processed 151 texts\n",
      "Saving data to disk from index 151 texts\n",
      "Processed 161 texts\n",
      "Processed 171 texts\n",
      "Processed 181 texts\n",
      "Processed 191 texts\n",
      "Processed 201 texts\n",
      "Saving data to disk from index 201 texts\n",
      "Processed 211 texts\n",
      "Processed 221 texts\n",
      "Processed 231 texts\n",
      "Processed 241 texts\n",
      "Processed 251 texts\n",
      "Saving data to disk from index 251 texts\n",
      "Processed 261 texts\n",
      "Processed 271 texts\n",
      "Processed 281 texts\n",
      "Processed 291 texts\n",
      "Processed 301 texts\n",
      "Saving data to disk from index 301 texts\n",
      "Processed 311 texts\n",
      "Processed 321 texts\n",
      "Processed 331 texts\n",
      "Processed 341 texts\n",
      "Processed 351 texts\n",
      "Saving data to disk from index 351 texts\n",
      "Processed 361 texts\n",
      "Processed 371 texts\n",
      "Processed 381 texts\n",
      "Processed 391 texts\n",
      "Processed 401 texts\n",
      "Saving data to disk from index 401 texts\n",
      "Processed 411 texts\n",
      "Processed 421 texts\n",
      "Processed 431 texts\n",
      "Processed 441 texts\n",
      "Processed 451 texts\n",
      "Saving data to disk from index 451 texts\n",
      "Processed 461 texts\n",
      "Processed 471 texts\n",
      "Processed 481 texts\n",
      "Processed 491 texts\n",
      "Processed 501 texts\n",
      "Saving data to disk from index 501 texts\n",
      "Processed 511 texts\n",
      "Processed 521 texts\n",
      "Processed 531 texts\n",
      "Processed 541 texts\n",
      "Processed 551 texts\n",
      "Saving data to disk from index 551 texts\n",
      "Processed 561 texts\n",
      "Processed 571 texts\n",
      "Processed 581 texts\n",
      "Processed 591 texts\n",
      "Processed 601 texts\n",
      "Saving data to disk from index 601 texts\n",
      "Processed 611 texts\n",
      "Processed 621 texts\n"
     ]
    }
   ],
   "source": [
    "# tager ca 16 min\n",
    "nouns,verbs = [],[]\n",
    "for index,row in df.iterrows():\n",
    "    try:\n",
    "        doc = nlp(row['text'])\n",
    "    except:\n",
    "        print(f\"Error processing letter {row['id']}\")\n",
    "        print(row)\n",
    "        throw\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'NOUN':\n",
    "            nouns.append(token.text)\n",
    "        elif token.pos_ == 'VERB':\n",
    "            verbs.append(token.text)\n",
    "    \n",
    "    if (index) % 100 == 0:\n",
    "        print(f\"Processed {index + 1} letters\")      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a little bit of cleaning\n",
    "nouns = [x for x in nouns if x != ' ']\n",
    "nouns = [x for x in nouns if x != '.']\n",
    "verbs = [x for x in verbs if x != ' ']\n",
    "\n",
    "# lowercase everything\n",
    "nouns = [x.lower() for x in nouns]\n",
    "verbs = [x.lower() for x in verbs]\n",
    "\n",
    "dfnouns = pd.DataFrame(nouns,columns=['nouns'])\n",
    "dfnouns.to_csv(f'data/nouns.csv')\n",
    "dfverbs = pd.DataFrame(verbs,columns=['verbs'])\n",
    "dfverbs.to_csv(f'data/verbs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency\n",
    "from collections import Counter\n",
    "cnouns = Counter(nouns)\n",
    "cverbs = Counter(verbs)\n",
    "cnouns.most_common()\n",
    "\n",
    "dfnounfreq = pd.DataFrame(cnouns.most_common(),columns=['noun','freq'])\n",
    "dfnounfreq.to_csv(f'data/nounfreq.csv',index=False)\n",
    "\n",
    "dfverbfreq = pd.DataFrame(cverbs.most_common(),columns=['verb','freq'])\n",
    "dfverbfreq.to_csv(f'data/verbfreq.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dag</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aften</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tak</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dage</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brev</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>tvivl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4344</th>\n",
       "      <td>maas-talen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4345</th>\n",
       "      <td>skjorten</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>tjæneste-rejse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4347</th>\n",
       "      <td>10.dage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4348 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                noun  freq\n",
       "0                dag   856\n",
       "1              aften   560\n",
       "2                tak   515\n",
       "3               dage   503\n",
       "4               brev   496\n",
       "...              ...   ...\n",
       "4343           tvivl     1\n",
       "4344      maas-talen     1\n",
       "4345        skjorten     1\n",
       "4346  tjæneste-rejse     1\n",
       "4347         10.dage     1\n",
       "\n",
       "[4348 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nounfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for each letter, extract verbs\n",
    "# for letter in df['text']:\n",
    "#     doc = nlp(letter)\n",
    "#     verbs.append([token.text for token in doc if token.pos_ == 'VERB'])\n",
    "#     nouns.append([token.text for token in doc if token.pos_ == 'NOUN'])\n",
    "\n",
    "# df_verbs = pd.DataFrame(verbs)\n",
    "# df_verbs.to_csv('data/verbs.csv', index=False)\n",
    "# df_nouns = pd.DataFrame(nouns)\n",
    "# df_nouns.to_csv('data/nouns.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten nouns and verbs\n",
    "#nouns = [item for sublist in nouns for item in sublist]\n",
    "#nouns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jernkors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
