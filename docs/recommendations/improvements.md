# Jernkorset Improvement Recommendations

> Generated: February 2026

This document outlines recommended improvements for the Jernkorset project, organized by priority level.

---

## High Priority

### 1. API Error Handling & Validation

**Current State**: The FastAPI backend has minimal error handling. Invalid letter IDs return generic errors.

**Recommendations**:
- Add Pydantic models for request/response validation
- Implement proper HTTP status codes (404 for missing letters, 400 for bad requests)
- Add structured error responses with error codes
- Log errors with context for debugging

**Files to modify**: `webapp/api/main.py`

---

### 2. Database Migration (CSV → SQLite/PostgreSQL)

**Current State**: All data is stored in CSV files, loaded into memory on startup.

**Recommendations**:
- Migrate to SQLite for development (single file, zero config)
- Consider PostgreSQL for production (better concurrency, full-text search)
- Use SQLAlchemy ORM for database abstraction
- Add Alembic for schema migrations
- Benefits: Better query performance, ACID compliance, concurrent access

**Impact**: Improved scalability, query flexibility, and data integrity

---

### 3. Environment Configuration Cleanup

**Current State**: Hardcoded paths and configuration values scattered across notebooks and scripts.

**Recommendations**:
- Centralize all configuration in `.env` files
- Create `config.py` with pydantic-settings for validation
- Document all environment variables
- Add environment-specific configs (dev, staging, prod)

**Files to create**: `webapp/api/config.py`, `scripts/config.py`

---

### 4. Test Coverage

**Current State**: No automated tests exist for the API, scripts, or notebooks.

**Recommendations**:
- Add pytest for API testing
- Create fixtures for test data (sample letters, entities)
- Add integration tests for NLP pipeline
- Target 80%+ coverage for API endpoints
- Add pre-commit hooks to run tests

**Structure**:
```
tests/
├── api/
│   ├── test_letters.py
│   ├── test_places.py
│   └── test_proofread.py
├── scripts/
│   └── test_sentence_extractor.py
└── conftest.py
```

---

## Medium Priority

### 5. Full-Text Search Implementation ✅

**Current State**: No search functionality. Users must browse all 666 letters manually.

**Recommendations**:
- Add `/search` endpoint with query parameters
- Implement full-text search (SQLite FTS5 or PostgreSQL tsvector)
- Support filtering by: date range, sender, recipient, place
- Add pagination for results
- Consider Elasticsearch for advanced search features

**API Design**:
```
GET /search?q=kære&sender=Peter&from=1914-01-01&to=1914-12-31
```

---

### 6. Interactive Map Enhancement

**Current State**: Static map images generated by notebooks. No interactive exploration.

**Recommendations**:
- Add Leaflet.js or Mapbox GL to frontend
- Show letter locations with clustering for dense areas
- Timeline slider to filter by date
- Click markers to view letter excerpts
- Layer toggle for 1914 vs modern borders

**Integration**: Use existing `places.csv` and `places.geojson` data

---

### 7. Batch Text Modernization

**Current State**: Single-letter modernization only via `/proofread/{id}` endpoint.

**Recommendations**:
- Add batch endpoint: `POST /proofread/batch`
- Implement async processing with job queue
- Add progress tracking and status endpoint
- Cache modernized text to avoid re-processing
- Consider cost limits (Claude API usage)

---

### 8. Export Modernized Letters

**Current State**: Modernized text shown in UI only, not exportable.

**Recommendations**:
- Add export endpoints for EPUB/PDF with modernized text
- Store accepted modernizations in database
- Option to export original, modernized, or both side-by-side
- Include diff highlighting in PDF export

---

### 9. API Response Caching

**Current State**: Every request reads from CSV files.

**Recommendations**:
- Add Redis caching for frequently accessed data
- Cache letter list with 5-minute TTL
- Cache individual letters with longer TTL
- Invalidate cache on data updates
- Add cache headers for browser caching

---

## Lower Priority

### 10. Notebook Pipeline Orchestration

**Current State**: 16 notebooks must be run manually in sequence.

**Recommendations**:
- Create Makefile or CLI tool for pipeline execution
- Use Papermill for parameterized notebook runs
- Add Airflow/Prefect DAG for scheduling
- Document dependencies between notebooks
- Add checksums to skip unchanged steps

**Pipeline Dependencies**:
```
01_cleanup → 02_geodata, 03_sentences, 06_verbs, 08_epub, 10_places, 12_clusters
03_sentences → 04_NER, 05a_sentiment
10_places → 11_placemaps
```

---

### 11. Sentiment Analysis Dashboard

**Current State**: Sentiment data exists but lacks interactive visualization.

**Recommendations**:
- Add sentiment timeline chart to frontend
- Show sentiment by recipient (Trine vs parents)
- Correlate sentiment with war events
- Compare multiple sentiment models (AFINN, Sentida, BERT)
- Add statistical summaries

---

### 12. Named Entity Linking

**Current State**: NER extracts entities but doesn't link to knowledge bases.

**Recommendations**:
- Link person names to Wikidata when possible
- Link place names to GeoNames/Wikidata
- Enrich entity cards with Wikipedia summaries
- Show entity co-occurrence network
- Add entity disambiguation UI

---

### 13. Docker Compose Setup ✅ (Completed)

**Status**: Implemented in previous session.

**Deliverables**:
- `docker-compose.yml` with 4 services
- Dockerfiles for API, frontend, public-site
- Health checks and volume mounts
- Production nginx configuration
- Documentation in `docs/docker.md`

---

## Architecture Improvements

### 14. API Versioning

**Recommendations**:
- Add `/api/v1/` prefix to all endpoints
- Document API with OpenAPI/Swagger (FastAPI auto-generates)
- Add API changelog
- Plan deprecation strategy for breaking changes

---

### 15. Frontend State Management

**Current State**: Local React state, no global state management.

**Recommendations**:
- Add Zustand or Jotai for lightweight state
- Persist user preferences (theme, filters)
- Cache API responses client-side
- Add optimistic updates for modernization

---

### 16. Logging & Monitoring

**Recommendations**:
- Add structured logging (JSON format)
- Implement request tracing with correlation IDs
- Add health check endpoints with dependency status
- Consider Sentry for error tracking
- Add Prometheus metrics for API performance

---

## NLP Pipeline Improvements

### 17. Model Version Pinning

**Current State**: NLP models downloaded at runtime, versions not pinned.

**Recommendations**:
- Pin DaCy model version in requirements
- Document expected model behavior
- Add model version to output metadata
- Create reproducibility checklist

---

### 18. Historical Danish Language Model

**Current State**: Using modern Danish NLP models on 1911-1918 text.

**Recommendations**:
- Research historical Danish NLP resources
- Consider fine-tuning on historical texts
- Document known accuracy issues
- Add confidence scores to NER output

---

### 19. Incremental Processing

**Current State**: Full pipeline re-run required for any changes.

**Recommendations**:
- Track processing status per letter
- Add checksums for change detection
- Implement incremental NER/sentiment updates
- Store processing metadata (model version, timestamp)

---

## Implementation Roadmap

### Phase 1: Foundation (Recommended first)
1. Environment configuration cleanup (#3)
2. Test coverage (#4)
3. API error handling (#1)

### Phase 2: Core Features
4. Database migration (#2)
5. Full-text search (#5)
6. Interactive map (#6)

### Phase 3: Enhanced Experience
7. Batch modernization (#7)
8. Export features (#8)
9. Caching (#9)

### Phase 4: Advanced
10. Pipeline orchestration (#10)
11. Sentiment dashboard (#11)
12. Entity linking (#12)

---

## Summary

| Priority | Count | Focus Area |
|----------|-------|------------|
| High | 4 | Stability, testing, configuration |
| Medium | 5 | User-facing features |
| Lower | 4 | Automation, analytics |
| Architecture | 3 | Scalability, maintainability |
| NLP | 3 | Accuracy, reproducibility |

**Total**: 19 recommendations

The Docker Compose setup (#13) has already been implemented. The next recommended focus areas are:
1. **Testing** - Add pytest coverage for API
2. **Configuration** - Centralize environment management
3. **Search** - Enable users to find specific letters
