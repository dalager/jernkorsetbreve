{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import da_core_news_sm\n",
        "import re\n",
        "\n",
        "df_sentences = pd.read_csv('../data/sentences.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# text list from the worst\n",
        "# texts = worst.sentence.tolist()\n",
        "# tokens = nlp(texts[2])\n",
        "# tokens = [token.text for token in tokens]\n",
        "# #tokens\n",
        "# bert.predict(tokens, IOBformat=False)\n",
        "\n",
        "# extract named entities from the worst sentences\n",
        "# import spacy\n",
        "# import da_core_news_sm\n",
        "# nlp = da_core_news_sm.load()\n",
        "\n",
        "nlp = da_core_news_sm.load()\n",
        "\n",
        "def get_named_entities(text):\n",
        "    \"\"\"Extract named entities from text\"\"\"\n",
        "    # trim for whitespace, Bert does not like trailing whitespace. At all.\n",
        "    text = re.sub(r'\\x95', '', text)\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.text for token in doc]\n",
        "    preds = bert.predict(tokens, IOBformat=False)\n",
        "    return [(ent['text'], ent['type']) for ent in preds['entities']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "collector =[]# get named entities for each sentence\n",
        "bad_sentences=[]\n",
        "for index, row in df_sentences.iterrows():\n",
        "    text = row['sentence'].strip()\n",
        "    try:\n",
        "        ents = get_named_entities(text)\n",
        "        for ent in ents:\n",
        "            collector.append({'sentence_id': index, 'text': ent[0], 'type': ent[1]})\n",
        "    except Exception as e:\n",
        "        bad_sentences.append({'sentence_id': index, 'text': text})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(task='ner', \n",
        "               model='saattrupdan/nbailab-base-ner-scandi', \n",
        "               aggregation_strategy='first')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_named_entities_with_scandi(text):\n",
        "    \"\"\"Extract named entities from text\"\"\"\n",
        "    # trim for whitespace, Bert does not like trailing whitespace. At all.\n",
        "    text = re.sub(r'\\x95', '', text)\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "#    doc = nlp(text)\n",
        "#    tokens = [token.text for token in doc]\n",
        "    preds = ner(text)\n",
        "    return [(ent['word'], ent['entity_group']) for ent in preds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "expected string or bytes-like object",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\projects\\dalager\\jernkorsetbreve\\04_extract_named_entities.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/projects/dalager/jernkorsetbreve/04_extract_named_entities.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df_sentences\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/projects/dalager/jernkorsetbreve/04_extract_named_entities.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     text \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/projects/dalager/jernkorsetbreve/04_extract_named_entities.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     ents \u001b[39m=\u001b[39m get_named_entities_with_scandi(text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/projects/dalager/jernkorsetbreve/04_extract_named_entities.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m ent \u001b[39min\u001b[39;00m ents:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/projects/dalager/jernkorsetbreve/04_extract_named_entities.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         collector\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39msentence_id\u001b[39m\u001b[39m'\u001b[39m: index, \u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m: ent[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m: ent[\u001b[39m1\u001b[39m]})\n",
            "\u001b[1;32mc:\\projects\\dalager\\jernkorsetbreve\\04_extract_named_entities.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/projects/dalager/jernkorsetbreve/04_extract_named_entities.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Extract named entities from text\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/projects/dalager/jernkorsetbreve/04_extract_named_entities.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# trim for whitespace, Bert does not like trailing whitespace. At all.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/projects/dalager/jernkorsetbreve/04_extract_named_entities.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39;49msub(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mx95\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/projects/dalager/jernkorsetbreve/04_extract_named_entities.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/projects/dalager/jernkorsetbreve/04_extract_named_entities.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m, text)\n",
            "File \u001b[1;32mc:\\Users\\christian.dalager\\AppData\\Local\\anaconda3\\envs\\jernkors\\lib\\re.py:210\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msub\u001b[39m(pattern, repl, string, count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m    204\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[39m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\u001b[39m.\u001b[39;49msub(repl, string, count)\n",
            "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
          ]
        }
      ],
      "source": [
        "import re\n",
        "df_sentences = pd.read_csv('../data/sentences.csv')\n",
        "collector =[]# get named entities for each sentence\n",
        "bad_sentences=[]\n",
        "for index, row in df_sentences.iterrows():\n",
        "    text = row['sentence']\n",
        "    ents = get_named_entities_with_scandi(text)\n",
        "    for ent in ents:\n",
        "        collector.append({'sentence_id': index, 'text': ent[0], 'type': ent[1]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14234, 4)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_sentences.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ents = pd.DataFrame(collector)\n",
        "df_ents.to_csv('NER_entities_scandi.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_ents = pd.read_csv('../data/NER_entities.csv')\n",
        "# group and count per text and type\n",
        "grouped = df_ents.groupby(['text', 'type']).size().reset_index(name='counts').sort_values(by=['counts'], ascending=False)\n",
        "\n",
        "grouped.to_csv('../data/NER_entities_grouped.csv')\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "jernkors",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
